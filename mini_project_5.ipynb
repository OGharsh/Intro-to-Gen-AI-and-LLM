{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OGharsh/Intro-to-Gen-AI-and-LLM/blob/main/mini_project_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lQMN7B5FKR2S",
      "metadata": {
        "id": "lQMN7B5FKR2S"
      },
      "source": [
        "\n",
        "<center><font size=6>Introduction to Prompt Engineering</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HxgFkEuv1raU",
      "metadata": {
        "id": "HxgFkEuv1raU"
      },
      "source": [
        "<center><font size=6>Restaurant Review Analysis</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MzSKXh2LsOvd",
      "metadata": {
        "id": "MzSKXh2LsOvd"
      },
      "source": [
        "### Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "my--X4VNQsPd",
      "metadata": {
        "id": "my--X4VNQsPd"
      },
      "source": [
        "Manual analysis of unstructured text reviews is slow and unscalable.\n",
        "The company struggles to automatically extract and understand customer sentiments (positive, negative, or neutral) from this data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mgGZFBqvdX3_",
      "metadata": {
        "id": "mgGZFBqvdX3_"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Q0UjpRLUteW",
      "metadata": {
        "id": "5Q0UjpRLUteW"
      },
      "source": [
        "Build an automated sentiment analysis model using an LLM to predict customer sentiment, enabling data-driven insights and improved customer satisfaction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8pDl8uVKR2W",
      "metadata": {
        "id": "b8pDl8uVKR2W"
      },
      "source": [
        "## Installing and Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fN9ATQxwKR2W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN9ATQxwKR2W",
        "outputId": "8f091675-a4f3-403d-c12e-524d9b97cec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m264.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.6/515.6 kB\u001b[0m \u001b[31m351.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m337.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m389.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m171.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m281.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m311.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m281.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m206.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m367.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m219.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m306.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m195.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m198.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m350.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "transformers 4.57.1 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 1.1.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install llama-cpp-python==0.2.45 huggingface_hub -q --no-cache-dir --force-reinstall"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7QF-gRUmrL",
      "metadata": {
        "id": "4f7QF-gRUmrL"
      },
      "source": [
        "**Note**: pip's dependency error can be ignored as it does not affect further execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VFjHLA6SKR2W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFjHLA6SKR2W",
        "outputId": "0733af12-d562-4ba1-fb82-412307ea7743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (1.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.10.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub) (8.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# For downloading the models from HF Hub\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mOyQTXjGVZzW",
      "metadata": {
        "id": "mOyQTXjGVZzW"
      },
      "outputs": [],
      "source": [
        "# Importing library for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Function to download the model from the Hugging Face model hub\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Importing the Llama class from the llama_cpp module\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Importing the json module\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mv_4wV7dTNqQ",
      "metadata": {
        "id": "mv_4wV7dTNqQ"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TfpwypirdmDT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfpwypirdmDT",
        "outputId": "e1c77673-ba5c-497d-80ba-de707b80af5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vFDKop_1qcBQ",
      "metadata": {
        "id": "vFDKop_1qcBQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zb2dDd4ekE_V",
      "metadata": {
        "id": "zb2dDd4ekE_V"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/dataset/restaurant_reviews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H-51wMmpGzcr",
      "metadata": {
        "id": "H-51wMmpGzcr"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duHgKeWUqlzQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "duHgKeWUqlzQ",
        "outputId": "d224516f-3a1b-41c7-be5f-fcc5531d9fdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"We came across Perch by accident and had dinner there on two separate occasions, having enjoyed it so much the first time round. There is no doubt that it has a strong European emphasis, although results in fantastic, modern food and attentive service that was amongst the best that we've experienced here.  The Indian Sauvignon Blanc was very acceptable, rather than the more expensive European alternatives, and there was a good range of cocktails, mocktails and beers. Decor was stylish but simple, ambience was good with lively, tasteful music to suit the meal. All food we ordered was good, and we've taken a menu home to replicate some of our favourite dishes. Have two appetisers or one main each, a couple of puddings are good to share on a small table.  Half carafe of wine, half of Sangria, two beers, five appetisers and two puddings including taxes and service about £75. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data['review_full'][5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NA2wS2mVkK7X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NA2wS2mVkK7X",
        "outputId": "9b2818dd-2981-4443-a0fb-2ac089c97077"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  restaurant_ID  rating_review  \\\n",
              "0        FLV202              5   \n",
              "1        SAV303              5   \n",
              "2        YUM789              5   \n",
              "3        TST101              5   \n",
              "4        EAT456              5   \n",
              "\n",
              "                                         review_full  \n",
              "0  Totally in love with the Auro of the place, re...  \n",
              "1  Kailash colony is brimming with small cafes no...  \n",
              "2  Excellent taste and awesome decorum. Must visi...  \n",
              "3  I have visited at jw lough/restourant. There w...  \n",
              "4  Had a great experience in the restaurant food ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ff05166-14ab-4e8e-96f3-7a41d4d1df87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>restaurant_ID</th>\n",
              "      <th>rating_review</th>\n",
              "      <th>review_full</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FLV202</td>\n",
              "      <td>5</td>\n",
              "      <td>Totally in love with the Auro of the place, re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAV303</td>\n",
              "      <td>5</td>\n",
              "      <td>Kailash colony is brimming with small cafes no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>YUM789</td>\n",
              "      <td>5</td>\n",
              "      <td>Excellent taste and awesome decorum. Must visi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TST101</td>\n",
              "      <td>5</td>\n",
              "      <td>I have visited at jw lough/restourant. There w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EAT456</td>\n",
              "      <td>5</td>\n",
              "      <td>Had a great experience in the restaurant food ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ff05166-14ab-4e8e-96f3-7a41d4d1df87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ff05166-14ab-4e8e-96f3-7a41d4d1df87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ff05166-14ab-4e8e-96f3-7a41d4d1df87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-515ea8b1-76f6-4973-82c0-03a1ad880b45\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-515ea8b1-76f6-4973-82c0-03a1ad880b45')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-515ea8b1-76f6-4973-82c0-03a1ad880b45 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"restaurant_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"FLV202\",\n          \"PIZ555\",\n          \"CRV333\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating_review\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_full\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Totally in love with the Auro of the place, really beautiful and quite fancy at the same time. The ambience is very pure and gives a sense of positivity throughout. Outdoor and indoor interior are quite quaint and cute. Love the open kitchen idea and there whole marketplace ideology. Due to coronovirus they specifically use disposable cutlery to keep the pandemic in mind taking all the precautionary measures from the beginning of the place with the mask on their staff and using good sanitisation. The food is really amazing specially the pizza straight from the oven and the hummus and pita bread are quite delicious too. If you're looking for a classy yet soothing Italian place in Delhi,Fatjar is a go to for you!\",\n          \"Whilst staying at the Welcolmhotel Dwarka we visited Pavillion 75 expecting great things but we were disappointed. The place has great trip advisor reviews so we had high expectations that were sadly not met.  What really ruined our nice meal was the self service. A waiter gave us (a party of 5) two tablets to look at the menu on. Unlike with proper menus, where everyone can browse at their own speed we had to share a tablet between 5. We asked the waiter for more tablets and were given one. After we had eventually all used the tablets to browse and input our orders on to one tablet the tablet then had an error message and froze. We used the other tablet to order and that one ran out of battery. We were hungry after a long day travelling this was stressful. Eventually one of the waiters came over and took details of our order. I really disliked this way of ordering food, and would not use the restaurant again because of this.  The table was also dirty, there was dust and bits of fluff on the table and cloth napkins and my aunt was given a chipped glass which she discovered upon taking a drink. We told the waiter and he apologised and got us a new glass but again, this just really made our experience a disappointment.  Very disappointed as seems to have good reviews, maybe we came on a bad day but we didn't like the menu/way of ordering, the table was dirty and a member of our party was given a chipped glass.\",\n          \"SERVICE HORRENDOUS!!!!! Listen to the reviews. Sandwich was decent enough (maybe because I was soooo hungry after a hectic day out) well presented but the service put me off completely. 12 servers on the floor including the manager and not one person came over to check back to make sure all was okay with our meals. All hanging around talking. And when I say 12 that\\u2019s not even an exaggeration. Not a 5 star service. And certainly not a 5 star hotel. We did ask for bottled water and when poured in to a glass you could see tiny bubbles forming and microscopic imperfections on the glass because it was so warm. I asked for cold water and I was told they did not have any? I explained that I will not be drinking the warm water after waiting 15 minutes a new bottle came out...coldish.. 5 star ? And they do not have cold water! Ridiculous. Maybe for further tourist this could be a preference, cold water or temperature. 3700 rupees \\u20ac46 for two sandwiches, bottled water and terrible service! Certainly not worth it. I reckon the street food stalls would give a better service then here \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# checking the first five rows of the data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6fcfcf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "e6fcfcf5",
        "outputId": "07543ca1-24cb-4217-9572-a4948419dea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I have visited at jw lough/restourant. There were a first class service at lough, specially Ms.laxmi  who were superbed for handling the client need, me and my family lots enjoyed her specialty in the manner, and Laxmi is a very very good in the client service, I hope when I will come against I would definitely serve from Ms. Laxmi and she is wonderful girl in that service. See you again Ms. Laxmi for the your best service which I have received from you at jw lough/resourant. Thank you JW Marriott Hotel at Atrocity, Delhi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data['review_full'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m0E69LFPThSJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0E69LFPThSJ",
        "outputId": "0917c9ea-cd58-4a2a-9c03-34a7ee0e1e04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# checking the shape of the data\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "udY09oFqTm1B",
      "metadata": {
        "id": "udY09oFqTm1B"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- Data has 20 rows and 3 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qMV8hC_2G9aW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "qMV8hC_2G9aW",
        "outputId": "bc242438-9c06-4a33-f4e5-e6f6e68463e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "restaurant_ID    0\n",
              "rating_review    0\n",
              "review_full      0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>restaurant_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating_review</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_full</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# checking for missing values\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8zETWVmeHBIk",
      "metadata": {
        "id": "8zETWVmeHBIk"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- There are no missing values in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L5pIwimGK5_1",
      "metadata": {
        "id": "L5pIwimGK5_1"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jbaduRVymY3v",
      "metadata": {
        "id": "jbaduRVymY3v"
      },
      "source": [
        "### Loading the model (Llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61N9i3i8K5_9",
      "metadata": {
        "id": "61N9i3i8K5_9"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
        "model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\" # the model is in gguf format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ZpjCaMRVcM-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "482076d5afeb47ffbb65074c9fd3a9d3",
            "95883142419e42d68c08abebebc6a1c8",
            "6d73005a4d6a4977ae5d9e6922312ddc",
            "2b3c917ba8254b57a1d8c72b43967c4c",
            "42fd98a6d36c4beab4c83a089a5d2c26",
            "dce1d39ecec5429abf0f4722301dd7b3",
            "53c4aceafee74d60a37d5b163b2fad2a",
            "ef3b58253ba14966a4f784e9c89146e2",
            "70122b04cb544875a5c4670616f654b6",
            "b8e70a1ccf5e4fd082ec709966a35fcd",
            "8056317650ff4e2a91ac8ae0ee012016"
          ]
        },
        "id": "0ZpjCaMRVcM-",
        "outputId": "6de5617b-9391-4733-aefe-a25765546d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-13b-chat.Q5_K_M.gguf:   0%|          | 0.00/9.23G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "482076d5afeb47ffbb65074c9fd3a9d3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Using hf_hub_download to download a model from the Hugging Face model hub\n",
        "# The repo_id parameter specifies the model name or path in the Hugging Face repository\n",
        "# The filename parameter specifies the name of the file to download\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1SolgBhkVdgc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SolgBhkVdgc",
        "outputId": "87b574af-1761-42c5-a347-c933913fe2e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type q5_K:  241 tensors\n",
            "llama_model_loader: - type q6_K:   41 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 5120\n",
            "llm_load_print_meta: n_head           = 40\n",
            "llm_load_print_meta: n_head_kv        = 40\n",
            "llm_load_print_meta: n_layer          = 40\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
            "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 13824\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 13B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 13.02 B\n",
            "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  8801.63 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =  3200.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 3200.00 MiB, K (f16): 1600.00 MiB, V (f16): 1600.00 MiB\n",
            "llama_new_context_with_model:        CPU input buffer size   =    19.04 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   360.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n"
          ]
        }
      ],
      "source": [
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2,  # CPU cores\n",
        "    n_batch=512,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    # n_gpu_layers=43,  # uncomment and change this value based on GPU VRAM pool.\n",
        "    n_ctx=4096,  # Context window\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oWvf3R3An5K4",
      "metadata": {
        "id": "oWvf3R3An5K4"
      },
      "source": [
        "### Loading the model (Mistral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rF2F_YO_qGtV",
      "metadata": {
        "id": "rF2F_YO_qGtV"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uk2q7vrc_TrO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "e10da3e09df842f39e9d35e495b80fa2",
            "730842aebb4f4c899780aa9df301b8a0",
            "cfb4ba89ffe5492f82cf424bd1d928ff",
            "15bf83f7f2cb4d54b45f2671de69b62b",
            "883678895c1d447c8bedf6f22918ef0e",
            "618eadc69cd64850a931956f4a31f839",
            "540d607ce23e4f5fa1da5878bd03c8ac",
            "d5f29d30022e45ebba2657b274e4a3f7",
            "5d5f21a56aee4bfeaec7a8b7003272b6",
            "cae9b7e1b22044139218913923ed438e",
            "66e9c46f6c01479a917adb2e99e8631f"
          ]
        },
        "id": "Uk2q7vrc_TrO",
        "outputId": "d67692ac-5bab-468d-b092-e1f73d43f9e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q6_K.gguf:   0%|          | 0.00/5.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e10da3e09df842f39e9d35e495b80fa2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wI_T-0DWXRtD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI_T-0DWXRtD",
        "outputId": "b03e524f-1b8a-40c8-d0dc-6934d2f0ee46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q6_K\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 5.53 GiB (6.56 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
            "llm_load_tensors:        CPU buffer size =  5666.09 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 1024\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   128.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
            "llama_new_context_with_model:        CPU input buffer size   =    11.01 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    96.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n",
            "Using chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\n",
            "Using chat eos_token: \n",
            "Using chat bos_token: \n"
          ]
        }
      ],
      "source": [
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=1024,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VVXK7vYfmdkL",
      "metadata": {
        "id": "VVXK7vYfmdkL"
      },
      "source": [
        "### Defining Model Response Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5AfP0mcXVfXV",
      "metadata": {
        "id": "5AfP0mcXVfXV"
      },
      "outputs": [],
      "source": [
        "def generate_llama_response(instruction, review):\n",
        "\n",
        "    # System message explicitly instructing not to include the review text\n",
        "    system_message = \"\"\"\n",
        "        [INST]<<SYS>>\n",
        "        {}\n",
        "        <</SYS>>[/INST]\n",
        "    \"\"\".format(instruction)\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    prompt = f\"{review}\\n{system_message}\"\n",
        "\n",
        "    # Generate a response from the LLaMA model\n",
        "    response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        max_tokens=1024,\n",
        "        temperature=0,\n",
        "        top_p=0.95,\n",
        "        repeat_penalty=1.2,\n",
        "        top_k=50,\n",
        "        stop=['INST'],\n",
        "        echo=False,\n",
        "        seed=42,\n",
        "    )\n",
        "\n",
        "    # Extract the sentiment from the response\n",
        "    response_text = response[\"choices\"][0][\"text\"]\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SMXvOtlrmHJC",
      "metadata": {
        "id": "SMXvOtlrmHJC"
      },
      "source": [
        "- **`max_tokens`**: This parameter **specifies the maximum number of tokens that the model should generate** in response to the prompt.\n",
        "\n",
        "- **`temperature`**: This parameter **controls the randomness of the generated response**. A higher temperature value will result in a more random response, while a lower temperature value will result in a more predictable response.\n",
        "\n",
        "- **`top_p`**: This parameter **controls the diversity of the generated response by establishing a cumulative probability cutoff for token selection**. A higher value of top_p will result in a more diverse response, while a lower value will result in a less diverse response.\n",
        "\n",
        "- **`repeat_penalty`**: This parameter **controls the penalty for repeating tokens in the generated response**. A higher value of repeat_penalty will result in a lower probability of repeating tokens, while a lower value will result in a higher probability of repeating tokens.\n",
        "\n",
        "- **`top_k`**: This parameter **controls the maximum number of most-likely next tokens to consider** when generating the response at each step.\n",
        "\n",
        "- **`stop`**: This parameter is a **list of tokens that are used to dynamically stop response generation** whenever the tokens in the list are encountered.\n",
        "\n",
        "- **`echo`**: This parameter **controls whether the input (prompt) to the model should be returned** in the model response.\n",
        "\n",
        "- **`seed`**: This parameter **specifies a seed value that helps replicate results**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CHwEJ-hYjZyw",
      "metadata": {
        "id": "CHwEJ-hYjZyw"
      },
      "source": [
        "### Utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OWcEelJkO0uq",
      "metadata": {
        "id": "OWcEelJkO0uq"
      },
      "outputs": [],
      "source": [
        "# defining a function to parse the JSON output from the model\n",
        "def extract_json_data(json_str):\n",
        "    try:\n",
        "        # Find the indices of the opening and closing curly braces\n",
        "        json_start = json_str.find('{')\n",
        "        json_end = json_str.rfind('}')\n",
        "\n",
        "        if json_start != -1 and json_end != -1:\n",
        "            extracted_sentiment = json_str[json_start:json_end + 1]  # Extract the JSON object\n",
        "            data_dict = json.loads(extracted_sentiment)\n",
        "            return data_dict\n",
        "        else:\n",
        "            print(f\"Warning: JSON object not found in response: {json_str}\")\n",
        "            return {}\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing JSON: {e}\")\n",
        "        return {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BhARt3BUmHJA",
      "metadata": {
        "id": "BhARt3BUmHJA"
      },
      "source": [
        "## 1. Sentiment Analysis (Llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ifE2NALEmysV",
      "metadata": {
        "id": "ifE2NALEmysV"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data\n",
        "data_1 = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NaOpXQfumHJC",
      "metadata": {
        "id": "NaOpXQfumHJC"
      },
      "outputs": [],
      "source": [
        "# defining the instructions for the model\n",
        "instruction_1 = \"\"\"\n",
        "    You are an AI analyzing restaurant reviews. Classify the sentiment of the provided review into the following categories:\n",
        "    - Positive\n",
        "    - Negative\n",
        "    - Neutral\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "367lfafHmHJC",
      "metadata": {
        "id": "367lfafHmHJC"
      },
      "outputs": [],
      "source": [
        "data_1['model_response'] = data_1['review_full'].apply(lambda x: generate_llama_response(instruction_1, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76Ym659-m7yI",
      "metadata": {
        "id": "76Ym659-m7yI"
      },
      "outputs": [],
      "source": [
        "data_1['model_response'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "832fdf50",
      "metadata": {
        "id": "832fdf50"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iQEDE21ymHJD",
      "metadata": {
        "id": "iQEDE21ymHJD"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "print(data_1.loc[i, 'review_full'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dzuc2gsu4gCZ",
      "metadata": {
        "id": "Dzuc2gsu4gCZ"
      },
      "outputs": [],
      "source": [
        "print(data_1.loc[i, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_s0tz3CmmHJD",
      "metadata": {
        "id": "_s0tz3CmmHJD"
      },
      "outputs": [],
      "source": [
        "def extract_sentiment(model_response):\n",
        "    if 'positive' in model_response.lower():\n",
        "        return 'Positive'\n",
        "    elif 'negative' in model_response.lower():\n",
        "        return 'Negative'\n",
        "    elif 'neutral' in model_response.lower():\n",
        "        return 'Neutral'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_ie4vWp_mHJE",
      "metadata": {
        "id": "_ie4vWp_mHJE"
      },
      "outputs": [],
      "source": [
        "# applying the function to the model response\n",
        "data_1['sentiment'] = data_1['model_response'].apply(extract_sentiment)\n",
        "data_1['sentiment'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wdx85PqRf1H7",
      "metadata": {
        "id": "Wdx85PqRf1H7"
      },
      "outputs": [],
      "source": [
        "data_1['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BAajLpLOmHJF",
      "metadata": {
        "id": "BAajLpLOmHJF"
      },
      "outputs": [],
      "source": [
        "final_data_1 = data_1.drop(['model_response'], axis=1)\n",
        "final_data_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sq1Aq8BXajfg",
      "metadata": {
        "id": "sq1Aq8BXajfg"
      },
      "source": [
        "## 1. Sentiment Analysis (Mistral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ScqJfjzyajgD",
      "metadata": {
        "id": "ScqJfjzyajgD"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data\n",
        "data_1 = data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-rnRNMvh1IUL",
      "metadata": {
        "id": "-rnRNMvh1IUL"
      },
      "source": [
        "**We are going to use an instruction-tuned Mistral model. Hence, the format of the input to the model varies from that of Llama.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o1NHOv7fa5LU",
      "metadata": {
        "id": "o1NHOv7fa5LU"
      },
      "outputs": [],
      "source": [
        "#Defining the response funciton for Task 1.\n",
        "def response_1(prompt,review):\n",
        "    model_output = llm(\n",
        "      f\"\"\"\n",
        "      Q: {prompt}\n",
        "      Review: {review}\n",
        "      A:\n",
        "      \"\"\",\n",
        "      max_tokens=32,\n",
        "      stop=[\"Q:\", \"\\n\"],\n",
        "      temperature=0.01,\n",
        "      echo=False,\n",
        "    )\n",
        "\n",
        "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
        "\n",
        "    return temp_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kOCUHdAiajgE",
      "metadata": {
        "id": "kOCUHdAiajgE"
      },
      "outputs": [],
      "source": [
        "# defining the instructions for the model\n",
        "instruction_1 = \"\"\"\n",
        "    You are an AI analyzing restaurant reviews. Classify the sentiment of the provided review into the following categories:\n",
        "    - Positive\n",
        "    - Negative\n",
        "    - Neutral\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m4c3-lWwajgF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4c3-lWwajgF",
        "outputId": "033c133a-6734-4d69-b9f9-add7d2e43911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      21.77 ms /    32 runs   (    0.68 ms per token,  1470.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =  168072.43 ms /   218 tokens (  770.97 ms per token,     1.30 tokens per second)\n",
            "llama_print_timings:        eval time =   33306.20 ms /    31 runs   ( 1074.39 ms per token,     0.93 tokens per second)\n",
            "llama_print_timings:       total time =  201551.11 ms /   249 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.46 ms /    32 runs   (    0.70 ms per token,  1424.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =  168227.16 ms /   235 tokens (  715.86 ms per token,     1.40 tokens per second)\n",
            "llama_print_timings:        eval time =   31619.60 ms /    31 runs   ( 1019.99 ms per token,     0.98 tokens per second)\n",
            "llama_print_timings:       total time =  200019.59 ms /   266 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      25.52 ms /    32 runs   (    0.80 ms per token,  1254.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =   24520.32 ms /    34 tokens (  721.19 ms per token,     1.39 tokens per second)\n",
            "llama_print_timings:        eval time =   39515.47 ms /    31 runs   ( 1274.69 ms per token,     0.78 tokens per second)\n",
            "llama_print_timings:       total time =   64225.98 ms /    65 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.42 ms /    32 runs   (    0.70 ms per token,  1427.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =  100993.73 ms /   143 tokens (  706.25 ms per token,     1.42 tokens per second)\n",
            "llama_print_timings:        eval time =   31700.07 ms /    31 runs   ( 1022.58 ms per token,     0.98 tokens per second)\n",
            "llama_print_timings:       total time =  132860.75 ms /   174 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.18 ms /    32 runs   (    0.72 ms per token,  1380.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =  119631.90 ms /   169 tokens (  707.88 ms per token,     1.41 tokens per second)\n",
            "llama_print_timings:        eval time =   31802.79 ms /    31 runs   ( 1025.90 ms per token,     0.97 tokens per second)\n",
            "llama_print_timings:       total time =  151609.97 ms /   200 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.10 ms /    32 runs   (    0.72 ms per token,  1385.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =  151871.61 ms /   217 tokens (  699.87 ms per token,     1.43 tokens per second)\n",
            "llama_print_timings:        eval time =   32496.69 ms /    31 runs   ( 1048.28 ms per token,     0.95 tokens per second)\n",
            "llama_print_timings:       total time =  184544.78 ms /   248 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.12 ms /    32 runs   (    0.69 ms per token,  1446.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =  158638.69 ms /   215 tokens (  737.85 ms per token,     1.36 tokens per second)\n",
            "llama_print_timings:        eval time =   36820.21 ms /    31 runs   ( 1187.75 ms per token,     0.84 tokens per second)\n",
            "llama_print_timings:       total time =  195632.08 ms /   246 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =       2.52 ms /     4 runs   (    0.63 ms per token,  1589.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =   47909.87 ms /    69 tokens (  694.35 ms per token,     1.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3008.53 ms /     3 runs   ( 1002.84 ms per token,     1.00 tokens per second)\n",
            "llama_print_timings:       total time =   50936.42 ms /    72 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.28 ms /    32 runs   (    0.73 ms per token,  1374.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =   47686.36 ms /    67 tokens (  711.74 ms per token,     1.41 tokens per second)\n",
            "llama_print_timings:        eval time =   31286.71 ms /    31 runs   ( 1009.25 ms per token,     0.99 tokens per second)\n",
            "llama_print_timings:       total time =   79146.52 ms /    98 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.02 ms /    32 runs   (    0.69 ms per token,  1453.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =   47256.87 ms /    68 tokens (  694.95 ms per token,     1.44 tokens per second)\n",
            "llama_print_timings:        eval time =   32789.81 ms /    31 runs   ( 1057.74 ms per token,     0.95 tokens per second)\n",
            "llama_print_timings:       total time =   80209.70 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.27 ms /    32 runs   (    0.70 ms per token,  1437.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =   46657.97 ms /    65 tokens (  717.81 ms per token,     1.39 tokens per second)\n",
            "llama_print_timings:        eval time =   31844.96 ms /    31 runs   ( 1027.26 ms per token,     0.97 tokens per second)\n",
            "llama_print_timings:       total time =   78671.54 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =       2.73 ms /     4 runs   (    0.68 ms per token,  1463.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =   48865.83 ms /    71 tokens (  688.25 ms per token,     1.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2913.75 ms /     3 runs   (  971.25 ms per token,     1.03 tokens per second)\n",
            "llama_print_timings:       total time =   51799.26 ms /    74 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =       2.92 ms /     4 runs   (    0.73 ms per token,  1367.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =   45223.22 ms /    64 tokens (  706.61 ms per token,     1.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3498.26 ms /     3 runs   ( 1166.09 ms per token,     0.86 tokens per second)\n",
            "llama_print_timings:       total time =   48748.56 ms /    67 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =       2.14 ms /     3 runs   (    0.71 ms per token,  1403.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =  261183.34 ms /   354 tokens (  737.81 ms per token,     1.36 tokens per second)\n",
            "llama_print_timings:        eval time =    6448.46 ms /     2 runs   ( 3224.23 ms per token,     0.31 tokens per second)\n",
            "llama_print_timings:       total time =  267660.92 ms /   356 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =       2.57 ms /     3 runs   (    0.86 ms per token,  1165.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =  382716.46 ms /   526 tokens (  727.60 ms per token,     1.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2546.72 ms /     2 runs   ( 1273.36 ms per token,     0.79 tokens per second)\n",
            "llama_print_timings:       total time =  385295.96 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =       2.21 ms /     3 runs   (    0.74 ms per token,  1354.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =  203687.14 ms /   274 tokens (  743.38 ms per token,     1.35 tokens per second)\n",
            "llama_print_timings:        eval time =    9388.41 ms /     2 runs   ( 4694.20 ms per token,     0.21 tokens per second)\n",
            "llama_print_timings:       total time =  213094.29 ms /   276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.83 ms /    32 runs   (    0.71 ms per token,  1401.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =  201695.62 ms /   284 tokens (  710.20 ms per token,     1.41 tokens per second)\n",
            "llama_print_timings:        eval time =   32868.20 ms /    31 runs   ( 1060.26 ms per token,     0.94 tokens per second)\n",
            "llama_print_timings:       total time =  234747.06 ms /   315 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.84 ms /    32 runs   (    0.71 ms per token,  1401.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =  241672.48 ms /   335 tokens (  721.41 ms per token,     1.39 tokens per second)\n",
            "llama_print_timings:        eval time =   32632.87 ms /    31 runs   ( 1052.67 ms per token,     0.95 tokens per second)\n",
            "llama_print_timings:       total time =  274482.07 ms /   366 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.05 ms /    32 runs   (    0.69 ms per token,  1451.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =  346446.90 ms /   462 tokens (  749.89 ms per token,     1.33 tokens per second)\n",
            "llama_print_timings:        eval time =   33126.18 ms /    31 runs   ( 1068.59 ms per token,     0.94 tokens per second)\n",
            "llama_print_timings:       total time =  379758.15 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      24.37 ms /    32 runs   (    0.76 ms per token,  1313.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =  216506.16 ms /   297 tokens (  728.98 ms per token,     1.37 tokens per second)\n",
            "llama_print_timings:        eval time =   51357.45 ms /    31 runs   ( 1656.69 ms per token,     0.60 tokens per second)\n",
            "llama_print_timings:       total time =  268069.29 ms /   328 tokens\n"
          ]
        }
      ],
      "source": [
        "data_1['model_response'] = data_1['review_full'].apply(lambda x: response_1(instruction_1, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZD036AJSajgG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ZD036AJSajgG",
        "outputId": "d96c6a4e-7a73-4041-8c62-72950f6162f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     This review expresses a very positive sentime...\n",
              "1     Based on the given review, the sentiment can ...\n",
              "2     The sentiment expressed in this review is pos...\n",
              "3     Based on the given review, it can be classifi...\n",
              "4     This review expresses a very positive sentime...\n",
              "Name: model_response, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This review expresses a very positive sentime...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Based on the given review, the sentiment can ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The sentiment expressed in this review is pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Based on the given review, it can be classifi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This review expresses a very positive sentime...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data_1['model_response'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B4xz7jZmajgH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4xz7jZmajgH",
        "outputId": "ba666dd6-9fc0-45d5-e10c-674736eb6a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent taste and awesome decorum. Must visit. Subham Barnwal had given us a great service. One of the best experience.\n"
          ]
        }
      ],
      "source": [
        "i = 2\n",
        "print(data_1.loc[i, 'review_full'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fsAehjb6ajgI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsAehjb6ajgI",
        "outputId": "074d37a8-f723-4264-c74e-f10b9f16785b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The sentiment expressed in this review is positive. The use of words like \"excellent taste,\" \"awesome decorum,\" \"must visit,\" \"g\n"
          ]
        }
      ],
      "source": [
        "print(data_1.loc[i, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bckp7sqXajgI",
      "metadata": {
        "id": "Bckp7sqXajgI"
      },
      "outputs": [],
      "source": [
        "def extract_sentiment(model_response):\n",
        "    if 'positive' in model_response.lower():\n",
        "        return 'Positive'\n",
        "    elif 'negative' in model_response.lower():\n",
        "        return 'Negative'\n",
        "    elif 'neutral' in model_response.lower():\n",
        "        return 'Neutral'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RzZQ9ZZTajgJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "RzZQ9ZZTajgJ",
        "outputId": "653c3610-2a9a-45da-f283-db442fb05ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Positive\n",
              "1    Positive\n",
              "2    Positive\n",
              "3    Positive\n",
              "4    Positive\n",
              "Name: sentiment, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# applying the function to the model response\n",
        "data_1['sentiment'] = data_1['model_response'].apply(extract_sentiment)\n",
        "data_1['sentiment'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t4yh3oF1ajgK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "t4yh3oF1ajgK",
        "outputId": "a704f7aa-9ae1-4ba4-fcc8-0a03906a13c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "Positive    8\n",
              "Negative    7\n",
              "Neutral     5\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Positive</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Negative</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neutral</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "data_1['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2mgE55M2ajgL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2mgE55M2ajgL",
        "outputId": "dccf96e9-ad93-43b3-9ba4-dabde73882d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  restaurant_ID  rating_review  \\\n",
              "0        FLV202              5   \n",
              "1        SAV303              5   \n",
              "2        YUM789              5   \n",
              "3        TST101              5   \n",
              "4        EAT456              5   \n",
              "\n",
              "                                         review_full sentiment  \n",
              "0  Totally in love with the Auro of the place, re...  Positive  \n",
              "1  Kailash colony is brimming with small cafes no...  Positive  \n",
              "2  Excellent taste and awesome decorum. Must visi...  Positive  \n",
              "3  I have visited at jw lough/restourant. There w...  Positive  \n",
              "4  Had a great experience in the restaurant food ...  Positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ef7d844-6b50-4465-9951-0c89158c6231\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>restaurant_ID</th>\n",
              "      <th>rating_review</th>\n",
              "      <th>review_full</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FLV202</td>\n",
              "      <td>5</td>\n",
              "      <td>Totally in love with the Auro of the place, re...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAV303</td>\n",
              "      <td>5</td>\n",
              "      <td>Kailash colony is brimming with small cafes no...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>YUM789</td>\n",
              "      <td>5</td>\n",
              "      <td>Excellent taste and awesome decorum. Must visi...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TST101</td>\n",
              "      <td>5</td>\n",
              "      <td>I have visited at jw lough/restourant. There w...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EAT456</td>\n",
              "      <td>5</td>\n",
              "      <td>Had a great experience in the restaurant food ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ef7d844-6b50-4465-9951-0c89158c6231')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ef7d844-6b50-4465-9951-0c89158c6231 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ef7d844-6b50-4465-9951-0c89158c6231');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0f508e1b-642b-4daf-b0c0-5a91101fb756\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f508e1b-642b-4daf-b0c0-5a91101fb756')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0f508e1b-642b-4daf-b0c0-5a91101fb756 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_data_1",
              "summary": "{\n  \"name\": \"final_data_1\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"restaurant_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"FLV202\",\n          \"PIZ555\",\n          \"CRV333\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating_review\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_full\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Totally in love with the Auro of the place, really beautiful and quite fancy at the same time. The ambience is very pure and gives a sense of positivity throughout. Outdoor and indoor interior are quite quaint and cute. Love the open kitchen idea and there whole marketplace ideology. Due to coronovirus they specifically use disposable cutlery to keep the pandemic in mind taking all the precautionary measures from the beginning of the place with the mask on their staff and using good sanitisation. The food is really amazing specially the pizza straight from the oven and the hummus and pita bread are quite delicious too. If you're looking for a classy yet soothing Italian place in Delhi,Fatjar is a go to for you!\",\n          \"Whilst staying at the Welcolmhotel Dwarka we visited Pavillion 75 expecting great things but we were disappointed. The place has great trip advisor reviews so we had high expectations that were sadly not met.  What really ruined our nice meal was the self service. A waiter gave us (a party of 5) two tablets to look at the menu on. Unlike with proper menus, where everyone can browse at their own speed we had to share a tablet between 5. We asked the waiter for more tablets and were given one. After we had eventually all used the tablets to browse and input our orders on to one tablet the tablet then had an error message and froze. We used the other tablet to order and that one ran out of battery. We were hungry after a long day travelling this was stressful. Eventually one of the waiters came over and took details of our order. I really disliked this way of ordering food, and would not use the restaurant again because of this.  The table was also dirty, there was dust and bits of fluff on the table and cloth napkins and my aunt was given a chipped glass which she discovered upon taking a drink. We told the waiter and he apologised and got us a new glass but again, this just really made our experience a disappointment.  Very disappointed as seems to have good reviews, maybe we came on a bad day but we didn't like the menu/way of ordering, the table was dirty and a member of our party was given a chipped glass.\",\n          \"SERVICE HORRENDOUS!!!!! Listen to the reviews. Sandwich was decent enough (maybe because I was soooo hungry after a hectic day out) well presented but the service put me off completely. 12 servers on the floor including the manager and not one person came over to check back to make sure all was okay with our meals. All hanging around talking. And when I say 12 that\\u2019s not even an exaggeration. Not a 5 star service. And certainly not a 5 star hotel. We did ask for bottled water and when poured in to a glass you could see tiny bubbles forming and microscopic imperfections on the glass because it was so warm. I asked for cold water and I was told they did not have any? I explained that I will not be drinking the warm water after waiting 15 minutes a new bottle came out...coldish.. 5 star ? And they do not have cold water! Ridiculous. Maybe for further tourist this could be a preference, cold water or temperature. 3700 rupees \\u20ac46 for two sandwiches, bottled water and terrible service! Certainly not worth it. I reckon the street food stalls would give a better service then here \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Positive\",\n          \"Neutral\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "final_data_1 = data_1.drop(['model_response'], axis=1)\n",
        "final_data_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ixmkBFZjh3Uu",
      "metadata": {
        "id": "ixmkBFZjh3Uu"
      },
      "source": [
        "## 2. Sentiment Analysis and Returning Structured Output (Llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mgee5PGLnhNr",
      "metadata": {
        "id": "Mgee5PGLnhNr"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data\n",
        "data_2 = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kjDHDEs0cX5U",
      "metadata": {
        "id": "kjDHDEs0cX5U"
      },
      "outputs": [],
      "source": [
        "# defining the instructions for the model\n",
        "instruction_2 = \"\"\"\n",
        "    You are an AI analyzing restaurant reviews. Classify the sentiment of the provided review into the following categories:\n",
        "    - Positive\n",
        "    - Negative\n",
        "    - Neutral\n",
        "\n",
        "    Format the output as a JSON object with a single key-value pair as shown below:\n",
        "    {\"sentiment\": \"your_sentiment_prediction\"}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SqtxeTOnh3VE",
      "metadata": {
        "id": "SqtxeTOnh3VE"
      },
      "outputs": [],
      "source": [
        "data_2['model_response'] = data_2['review_full'].apply(lambda x: generate_llama_response(instruction_2, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P2Zf6SsN4bsJ",
      "metadata": {
        "id": "P2Zf6SsN4bsJ"
      },
      "outputs": [],
      "source": [
        "data_2['model_response'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sj9Kw8LLh3VF",
      "metadata": {
        "id": "Sj9Kw8LLh3VF"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "print(data_2.loc[i, 'review_full'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bxv3poEE4n3n",
      "metadata": {
        "id": "Bxv3poEE4n3n"
      },
      "outputs": [],
      "source": [
        "print(data_2.loc[i, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A6Zo_YDch3VG",
      "metadata": {
        "id": "A6Zo_YDch3VG"
      },
      "outputs": [],
      "source": [
        "# applying the function to the model response\n",
        "data_2['model_response_parsed'] = data_2['model_response'].apply(extract_json_data)\n",
        "data_2['model_response_parsed'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qFPR8vPAh3VH",
      "metadata": {
        "id": "qFPR8vPAh3VH"
      },
      "outputs": [],
      "source": [
        "model_response_parsed_df_2 = pd.json_normalize(data_2['model_response_parsed'])\n",
        "model_response_parsed_df_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NX-zy5BTh3VH",
      "metadata": {
        "id": "NX-zy5BTh3VH"
      },
      "outputs": [],
      "source": [
        "data_with_parsed_model_output_2 = pd.concat([data_2, model_response_parsed_df_2], axis=1)\n",
        "data_with_parsed_model_output_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6hiEw_Znh3VI",
      "metadata": {
        "id": "6hiEw_Znh3VI"
      },
      "outputs": [],
      "source": [
        "final_data_2 = data_with_parsed_model_output_2.drop(['model_response','model_response_parsed'], axis=1)\n",
        "final_data_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xuZttnsMos6g",
      "metadata": {
        "id": "xuZttnsMos6g"
      },
      "outputs": [],
      "source": [
        "final_data_2['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HslGURoah3VI",
      "metadata": {
        "id": "HslGURoah3VI"
      },
      "source": [
        "## 3. Identifying Overall Sentiment and Sentiment of Aspects of the Experience (Llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MZcG8ygIn2qy",
      "metadata": {
        "id": "MZcG8ygIn2qy"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data\n",
        "data_3 = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YhdIDYq4lf3C",
      "metadata": {
        "id": "YhdIDYq4lf3C"
      },
      "outputs": [],
      "source": [
        "# defining the instructions for the model\n",
        "instruction_3 = \"\"\"\n",
        "    You are an AI analyzing restaurant reviews. Classify the overall sentiment of the provided review into the following categories:\n",
        "    - \"Positive\"\n",
        "    - \"Negative\"\n",
        "    - \"Neutral\"\n",
        "\n",
        "    Once that is done, check for a mention of the following aspects in the review and classify the sentiment of each aspect as \"Positive\", \"Negative\", or \"Neutral\":\n",
        "    1. \"Food Quality\"\n",
        "    2. \"Service\"\n",
        "    3. \"Ambience\"\n",
        "\n",
        "    Output the overall sentiment and sentiment for each category in a JSON format with the following keys:\n",
        "    {\n",
        "        \"Overall\": \"your_sentiment_prediction\",\n",
        "        \"Food Quality\": \"your_sentiment_prediction\",\n",
        "        \"Service\": \"your_sentiment_prediction\",\n",
        "        \"Ambience\": \"your_sentiment_prediction\"\n",
        "    }\n",
        "\n",
        "    In case one of the three aspects is not mentioned in the review, set \"Not Applicable\" (including quotes) for the corresponding JSON key value.\n",
        "    Only return the JSON, do not return any other information.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vOmka93ilf3O",
      "metadata": {
        "id": "vOmka93ilf3O"
      },
      "outputs": [],
      "source": [
        "data_3['model_response'] = data_3['review_full'].apply(lambda x: generate_llama_response(instruction_3, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IwAEYkStbUjv",
      "metadata": {
        "id": "IwAEYkStbUjv"
      },
      "outputs": [],
      "source": [
        "data_3['model_response'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FnfnhInbup2A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnfnhInbup2A",
        "outputId": "8de6bd8b-2b0b-4956-af63-ed8883c2609c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent taste and awesome decorum. Must visit. Subham Barnwal had given us a great service. One of the best experience.\n"
          ]
        }
      ],
      "source": [
        "i = 2\n",
        "print(data_3.loc[i, 'review_full'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tAqbJ5Hs4v-A",
      "metadata": {
        "id": "tAqbJ5Hs4v-A"
      },
      "outputs": [],
      "source": [
        "print(data_3.loc[i, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1t7hUgimunU5",
      "metadata": {
        "id": "1t7hUgimunU5"
      },
      "outputs": [],
      "source": [
        "# applying the function to the model response\n",
        "data_3['model_response_parsed'] = data_3['model_response'].apply(extract_json_data)\n",
        "data_3['model_response_parsed'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sX_m53eLunVA",
      "metadata": {
        "id": "sX_m53eLunVA"
      },
      "outputs": [],
      "source": [
        "model_response_parsed_df_3 = pd.json_normalize(data_3['model_response_parsed'])\n",
        "model_response_parsed_df_3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B37cFr6punVB",
      "metadata": {
        "id": "B37cFr6punVB"
      },
      "outputs": [],
      "source": [
        "data_with_parsed_model_output_3 = pd.concat([data_3, model_response_parsed_df_3], axis=1)\n",
        "data_with_parsed_model_output_3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kMDwOWVPunVB",
      "metadata": {
        "id": "kMDwOWVPunVB"
      },
      "outputs": [],
      "source": [
        "final_data_3 = data_with_parsed_model_output_3.drop(['model_response','model_response_parsed'], axis=1)\n",
        "final_data_3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gkyB71hC22kS",
      "metadata": {
        "id": "gkyB71hC22kS"
      },
      "outputs": [],
      "source": [
        "final_data_3['Overall'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uQ__aM1Hcy00",
      "metadata": {
        "id": "uQ__aM1Hcy00"
      },
      "outputs": [],
      "source": [
        "final_data_3['Food Quality'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ah3IRNDTcyxO",
      "metadata": {
        "id": "Ah3IRNDTcyxO"
      },
      "outputs": [],
      "source": [
        "final_data_3['Service'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hPQZOYwicyui",
      "metadata": {
        "id": "hPQZOYwicyui"
      },
      "outputs": [],
      "source": [
        "final_data_3['Ambience'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mf4lta2PbHS4",
      "metadata": {
        "id": "Mf4lta2PbHS4"
      },
      "source": [
        "## 3. Identifying Overall Sentiment and Sentiment of Aspects of the Experience (Mistral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZWwS7SIpbHTb",
      "metadata": {
        "id": "ZWwS7SIpbHTb"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data\n",
        "data_3 = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6N4lVvxkbz7Y",
      "metadata": {
        "id": "6N4lVvxkbz7Y"
      },
      "outputs": [],
      "source": [
        "def response_2(prompt,review,sentiment):\n",
        "    model_output = llm(\n",
        "      f\"\"\"\n",
        "      Q: {prompt}\n",
        "      review: {review}\n",
        "      sentiment: {sentiment}\n",
        "      A:\n",
        "      \"\"\",\n",
        "      max_tokens=64,\n",
        "      stop=[\"Q:\", \"\\n\"],\n",
        "      temperature=0.01,\n",
        "      echo=False,\n",
        "    )\n",
        "\n",
        "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
        "    final_output = temp_output[temp_output.index('{'):]\n",
        "\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "us5pXLe30NaB",
      "metadata": {
        "id": "us5pXLe30NaB"
      },
      "source": [
        "**Note:** We have already predicted the sentiment of the review. We can use this information while designing the prompt for this task. This way, it will reduce the computational complexity.\n",
        "\n",
        "The sentiment is stored in the 'final_data_1' dataframe which is from the TASK 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vmP6pXJQbHTc",
      "metadata": {
        "id": "vmP6pXJQbHTc"
      },
      "outputs": [],
      "source": [
        "# defining the instructions for the model\n",
        "instruction_3 = \"\"\"\n",
        "    You are provided a review and it's sentiment.\n",
        "\n",
        "    Instructions:\n",
        "    Classify the sentiment of each aspect as either of \"Positive\", \"Negative\", or \"Neutral\" only and not any other for the given review:\n",
        "    1. \"Food Quality\"\n",
        "    2. \"Service\"\n",
        "    3. \"Ambience\"\n",
        "    In case one of the three aspects is not mentioned in the review, return \"Not Applicable\" (including quotes) for the corresponding JSON key value.\n",
        "    Return the output in the format {\"Overall\": given sentiment input,\"Food Quality\": \"your_sentiment_prediction\",\"Service\": \"your_sentiment_prediction\",\"Ambience\": \"your_sentiment_prediction\"}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mBQruWc9bHTd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBQruWc9bHTd",
        "outputId": "8a96b1d1-185a-4b95-93a3-b099b6a92214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-399174068.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  data_3['model_response'] = final_data_1[['review_full','sentiment']].apply(lambda x: response_2(instruction_3, x[0],x[1]),axis=1)\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      21.09 ms /    31 runs   (    0.68 ms per token,  1469.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =  274547.53 ms /   341 tokens (  805.12 ms per token,     1.24 tokens per second)\n",
            "llama_print_timings:        eval time =   34113.44 ms /    30 runs   ( 1137.11 ms per token,     0.88 tokens per second)\n",
            "llama_print_timings:       total time =  308838.24 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.31 ms /    33 runs   (    0.71 ms per token,  1415.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =  177387.12 ms /   241 tokens (  736.05 ms per token,     1.36 tokens per second)\n",
            "llama_print_timings:        eval time =   33286.27 ms /    32 runs   ( 1040.20 ms per token,     0.96 tokens per second)\n",
            "llama_print_timings:       total time =  210870.22 ms /   273 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      21.55 ms /    31 runs   (    0.70 ms per token,  1438.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =   28042.31 ms /    40 tokens (  701.06 ms per token,     1.43 tokens per second)\n",
            "llama_print_timings:        eval time =   31061.74 ms /    30 runs   ( 1035.39 ms per token,     0.97 tokens per second)\n",
            "llama_print_timings:       total time =   59267.20 ms /    70 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      24.91 ms /    35 runs   (    0.71 ms per token,  1405.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =  111149.92 ms /   149 tokens (  745.97 ms per token,     1.34 tokens per second)\n",
            "llama_print_timings:        eval time =   35355.63 ms /    34 runs   ( 1039.87 ms per token,     0.96 tokens per second)\n",
            "llama_print_timings:       total time =  146700.32 ms /   183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.26 ms /    33 runs   (    0.67 ms per token,  1482.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =  123729.74 ms /   175 tokens (  707.03 ms per token,     1.41 tokens per second)\n",
            "llama_print_timings:        eval time =   32916.10 ms /    32 runs   ( 1028.63 ms per token,     0.97 tokens per second)\n",
            "llama_print_timings:       total time =  156819.56 ms /   207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.45 ms /    31 runs   (    0.72 ms per token,  1380.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =  158263.35 ms /   223 tokens (  709.70 ms per token,     1.41 tokens per second)\n",
            "llama_print_timings:        eval time =   31302.30 ms /    30 runs   ( 1043.41 ms per token,     0.96 tokens per second)\n",
            "llama_print_timings:       total time =  189742.28 ms /   253 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.22 ms /    32 runs   (    0.69 ms per token,  1439.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =  155888.27 ms /   221 tokens (  705.38 ms per token,     1.42 tokens per second)\n",
            "llama_print_timings:        eval time =   54833.00 ms /    31 runs   ( 1768.81 ms per token,     0.57 tokens per second)\n",
            "llama_print_timings:       total time =  210900.00 ms /   252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.31 ms /    34 runs   (    0.69 ms per token,  1458.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =   54325.62 ms /    76 tokens (  714.81 ms per token,     1.40 tokens per second)\n",
            "llama_print_timings:        eval time =   33814.05 ms /    33 runs   ( 1024.67 ms per token,     0.98 tokens per second)\n",
            "llama_print_timings:       total time =   88324.81 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      21.75 ms /    32 runs   (    0.68 ms per token,  1471.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =   52024.48 ms /    73 tokens (  712.66 ms per token,     1.40 tokens per second)\n",
            "llama_print_timings:        eval time =   31489.30 ms /    31 runs   ( 1015.78 ms per token,     0.98 tokens per second)\n",
            "llama_print_timings:       total time =   83680.03 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      36.60 ms /    35 runs   (    1.05 ms per token,   956.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =   53249.79 ms /    75 tokens (  710.00 ms per token,     1.41 tokens per second)\n",
            "llama_print_timings:        eval time =   44055.20 ms /    34 runs   ( 1295.74 ms per token,     0.77 tokens per second)\n",
            "llama_print_timings:       total time =   97575.15 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.16 ms /    33 runs   (    0.70 ms per token,  1424.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =   52488.73 ms /    72 tokens (  729.01 ms per token,     1.37 tokens per second)\n",
            "llama_print_timings:        eval time =   39932.62 ms /    32 runs   ( 1247.89 ms per token,     0.80 tokens per second)\n",
            "llama_print_timings:       total time =   92606.40 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.92 ms /    33 runs   (    0.72 ms per token,  1379.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =   56761.29 ms /    78 tokens (  727.71 ms per token,     1.37 tokens per second)\n",
            "llama_print_timings:        eval time =   41994.02 ms /    32 runs   ( 1312.31 ms per token,     0.76 tokens per second)\n",
            "llama_print_timings:       total time =   98954.88 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      22.67 ms /    32 runs   (    0.71 ms per token,  1411.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =   51648.60 ms /    71 tokens (  727.45 ms per token,     1.37 tokens per second)\n",
            "llama_print_timings:        eval time =   41889.21 ms /    31 runs   ( 1351.26 ms per token,     0.74 tokens per second)\n",
            "llama_print_timings:       total time =   93735.65 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      30.29 ms /    34 runs   (    0.89 ms per token,  1122.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =  271749.04 ms /   360 tokens (  754.86 ms per token,     1.32 tokens per second)\n",
            "llama_print_timings:        eval time =   44643.28 ms /    33 runs   ( 1352.83 ms per token,     0.74 tokens per second)\n",
            "llama_print_timings:       total time =  316674.35 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      28.99 ms /    33 runs   (    0.88 ms per token,  1138.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =  420281.99 ms /   532 tokens (  790.00 ms per token,     1.27 tokens per second)\n",
            "llama_print_timings:        eval time =   42196.32 ms /    32 runs   ( 1318.64 ms per token,     0.76 tokens per second)\n",
            "llama_print_timings:       total time =  462697.69 ms /   564 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.87 ms /    34 runs   (    0.70 ms per token,  1424.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =  202179.63 ms /   280 tokens (  722.07 ms per token,     1.38 tokens per second)\n",
            "llama_print_timings:        eval time =   43151.70 ms /    33 runs   ( 1307.63 ms per token,     0.76 tokens per second)\n",
            "llama_print_timings:       total time =  245536.03 ms /   313 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      31.20 ms /    35 runs   (    0.89 ms per token,  1121.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =  209427.87 ms /   290 tokens (  722.17 ms per token,     1.38 tokens per second)\n",
            "llama_print_timings:        eval time =   50792.45 ms /    34 runs   ( 1493.90 ms per token,     0.67 tokens per second)\n",
            "llama_print_timings:       total time =  260454.31 ms /   324 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.06 ms /    33 runs   (    0.70 ms per token,  1430.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =  248749.78 ms /   341 tokens (  729.47 ms per token,     1.37 tokens per second)\n",
            "llama_print_timings:        eval time =   41042.74 ms /    32 runs   ( 1282.59 ms per token,     0.78 tokens per second)\n",
            "llama_print_timings:       total time =  289986.40 ms /   373 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      21.92 ms /    31 runs   (    0.71 ms per token,  1414.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =  350893.72 ms /   468 tokens (  749.77 ms per token,     1.33 tokens per second)\n",
            "llama_print_timings:        eval time =   42680.27 ms /    30 runs   ( 1422.68 ms per token,     0.70 tokens per second)\n",
            "llama_print_timings:       total time =  393768.16 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =  168073.84 ms\n",
            "llama_print_timings:      sample time =      23.16 ms /    33 runs   (    0.70 ms per token,  1425.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =  223067.10 ms /   303 tokens (  736.20 ms per token,     1.36 tokens per second)\n",
            "llama_print_timings:        eval time =   39310.92 ms /    32 runs   ( 1228.47 ms per token,     0.81 tokens per second)\n",
            "llama_print_timings:       total time =  262579.06 ms /   335 tokens\n"
          ]
        }
      ],
      "source": [
        "data_3['model_response'] = final_data_1[['review_full','sentiment']].apply(lambda x: response_2(instruction_3, x[0],x[1]),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CvjebhnZbHTe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvjebhnZbHTe",
        "outputId": "3034fa11-4920-47e5-b55b-1f1d027ce500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['{\"Overall\": \"Positive\",\"Food Quality\": \"Positive\",\"Service\": \"Positive\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Positive\",\"Food Quality\": \"Positive\",\"Service\": \"Not Applicable\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Positive\",\"Food Quality\": \"Positive\",\"Service\": \"Positive\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Positive\",\"Food Quality\": \"Not Applicable\",\"Service\": \"Positive\",\"Ambience\": \"Not Applicable\"}',\n",
              "       '{\"Overall\": \"Positive\",\"Food Quality\": \"Positive\",\"Service\": \"Positive\",\"Ambience\": \"Not Applicable\"}',\n",
              "       '{\"Overall\": \"Positive\",\"Food Quality\": \"Positive\",\"Service\": \"Positive\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Positive\",\"Food Quality\": \"Neutral\",\"Service\": \"Positive\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Neutral\",\"Food Quality\": \"Average\",\"Service\": \"Negative\",\"Ambience\": \"Not Applicable\"}',\n",
              "       '{\"Overall\": \"Positive\",\"Food Quality\": \"Neutral\",\"Service\": \"Negative\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Neutral\",\"Food Quality\": \"If not exceptional\",\"Service\": \"Positive\",\"Ambience\": \"Not Applicable\"}',\n",
              "       '{\"Overall\": \"Neutral\",\"Food Quality\": \"Neutral\",\"Service\": \"Positive\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Neutral\",\"Food Quality\": \"Neutral\",\"Service\": \"Negative\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Neutral\",\"Food Quality\": \"Negative\",\"Service\": \"Positive\",\"Ambience\": \"Positive\"}',\n",
              "       '{\"Overall\": \"Negative\",\"Food Quality\": \"Not Applicable\",\"Service\": \"Negative\",\"Ambience\": \"Neutral\"}',\n",
              "       '{\"Overall\": \"Negative\",\"Food Quality\": \"Negative\",\"Service\": \"Negative\",\"Ambience\": \"Not Applicable\"}',\n",
              "       '{\"Overall\": \"Negative\",\"Food Quality\": \"Neutral\",\"Service\": \"Negative\",\"Ambience\": \"Not Applicable\"}',\n",
              "       '{\"Overall\": \"Negative\",\"Food Quality\": \"Not Applicable\",\"Service\": \"Negative\",\"Ambience\": \"Not Applicable\"}',\n",
              "       '{\"Overall\": \"Negative\",\"Food Quality\": \"Not Applicable\",\"Service\": \"Negative\",\"Ambience\": \"Negative\"}',\n",
              "       '{\"Overall\": \"Negative\",\"Food Quality\": \"Negative\",\"Service\": \"Negative\",\"Ambience\": \"Negative\"}',\n",
              "       '{\"Overall\": \"Negative\",\"Food Quality\": \"Positive\",\"Service\": \"Negative\",\"Ambience\": \"Not Applicable\"}'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "data_3['model_response'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r-t5e6gMbHTf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-t5e6gMbHTf",
        "outputId": "3eb9b027-1018-4383-cb26-36ffb928aa99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent taste and awesome decorum. Must visit. Subham Barnwal had given us a great service. One of the best experience.\n"
          ]
        }
      ],
      "source": [
        "i = 2\n",
        "print(data_3.loc[i, 'review_full'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h9yyFpQHbHTg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9yyFpQHbHTg",
        "outputId": "3f067be6-ab71-48e6-9b09-2f401bcdefc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"Overall\": \"Positive\",\"Food Quality\": \"Positive\",\"Service\": \"Positive\",\"Ambience\": \"Positive\"}\n"
          ]
        }
      ],
      "source": [
        "print(data_3.loc[i, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MuvmCV_DbHTh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "MuvmCV_DbHTh",
        "outputId": "aa28425a-d787-45f1-97c1-6e4802e368c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     {'Overall': 'Positive', 'Food Quality': 'Posit...\n",
              "1     {'Overall': 'Positive', 'Food Quality': 'Posit...\n",
              "2     {'Overall': 'Positive', 'Food Quality': 'Posit...\n",
              "3     {'Overall': 'Positive', 'Food Quality': 'Not A...\n",
              "4     {'Overall': 'Positive', 'Food Quality': 'Posit...\n",
              "5     {'Overall': 'Positive', 'Food Quality': 'Posit...\n",
              "6     {'Overall': 'Positive', 'Food Quality': 'Neutr...\n",
              "7     {'Overall': 'Neutral', 'Food Quality': 'Averag...\n",
              "8     {'Overall': 'Positive', 'Food Quality': 'Neutr...\n",
              "9     {'Overall': 'Neutral', 'Food Quality': 'If not...\n",
              "10    {'Overall': 'Neutral', 'Food Quality': 'Neutra...\n",
              "11    {'Overall': 'Neutral', 'Food Quality': 'Neutra...\n",
              "12    {'Overall': 'Neutral', 'Food Quality': 'Negati...\n",
              "13    {'Overall': 'Negative', 'Food Quality': 'Not A...\n",
              "14    {'Overall': 'Negative', 'Food Quality': 'Negat...\n",
              "15    {'Overall': 'Negative', 'Food Quality': 'Neutr...\n",
              "16    {'Overall': 'Negative', 'Food Quality': 'Not A...\n",
              "17    {'Overall': 'Negative', 'Food Quality': 'Not A...\n",
              "18    {'Overall': 'Negative', 'Food Quality': 'Negat...\n",
              "19    {'Overall': 'Negative', 'Food Quality': 'Posit...\n",
              "Name: model_response_parsed, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_response_parsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Not A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Neutr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'Overall': 'Neutral', 'Food Quality': 'Averag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Neutr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'Overall': 'Neutral', 'Food Quality': 'If not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'Overall': 'Neutral', 'Food Quality': 'Neutra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>{'Overall': 'Neutral', 'Food Quality': 'Neutra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>{'Overall': 'Neutral', 'Food Quality': 'Negati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>{'Overall': 'Negative', 'Food Quality': 'Not A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>{'Overall': 'Negative', 'Food Quality': 'Negat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>{'Overall': 'Negative', 'Food Quality': 'Neutr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>{'Overall': 'Negative', 'Food Quality': 'Not A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>{'Overall': 'Negative', 'Food Quality': 'Not A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>{'Overall': 'Negative', 'Food Quality': 'Negat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>{'Overall': 'Negative', 'Food Quality': 'Posit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# applying the function to the model response\n",
        "data_3['model_response_parsed'] = data_3['model_response'].apply(extract_json_data)\n",
        "data_3['model_response_parsed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D2T6_J8vbHTi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "D2T6_J8vbHTi",
        "outputId": "c7438955-83a3-4236-9583-9b0a4339c39f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Overall        Food Quality         Service        Ambience\n",
              "0   Positive            Positive        Positive        Positive\n",
              "1   Positive            Positive  Not Applicable        Positive\n",
              "2   Positive            Positive        Positive        Positive\n",
              "3   Positive      Not Applicable        Positive  Not Applicable\n",
              "4   Positive            Positive        Positive  Not Applicable\n",
              "5   Positive            Positive        Positive        Positive\n",
              "6   Positive             Neutral        Positive        Positive\n",
              "7    Neutral             Average        Negative  Not Applicable\n",
              "8   Positive             Neutral        Negative        Positive\n",
              "9    Neutral  If not exceptional        Positive  Not Applicable\n",
              "10   Neutral             Neutral        Positive        Positive\n",
              "11   Neutral             Neutral        Negative        Positive\n",
              "12   Neutral            Negative        Positive        Positive\n",
              "13  Negative      Not Applicable        Negative         Neutral\n",
              "14  Negative            Negative        Negative  Not Applicable\n",
              "15  Negative             Neutral        Negative  Not Applicable\n",
              "16  Negative      Not Applicable        Negative  Not Applicable\n",
              "17  Negative      Not Applicable        Negative        Negative\n",
              "18  Negative            Negative        Negative        Negative\n",
              "19  Negative            Positive        Negative  Not Applicable"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cc612ca-9046-4f10-92da-103788730cd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Food Quality</th>\n",
              "      <th>Service</th>\n",
              "      <th>Ambience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Average</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>If not exceptional</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cc612ca-9046-4f10-92da-103788730cd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cc612ca-9046-4f10-92da-103788730cd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cc612ca-9046-4f10-92da-103788730cd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d1c3063a-9fb5-43bf-a992-1a5264da8bc6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1c3063a-9fb5-43bf-a992-1a5264da8bc6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d1c3063a-9fb5-43bf-a992-1a5264da8bc6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_29ee49b3-8b15-47e8-b78b-148d03216c00\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_response_parsed_df_3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_29ee49b3-8b15-47e8-b78b-148d03216c00 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_response_parsed_df_3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "model_response_parsed_df_3",
              "summary": "{\n  \"name\": \"model_response_parsed_df_3\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Overall\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Positive\",\n          \"Neutral\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Food Quality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Positive\",\n          \"Not Applicable\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Service\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Positive\",\n          \"Not Applicable\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ambience\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Not Applicable\",\n          \"Negative\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model_response_parsed_df_3 = pd.json_normalize(data_3['model_response_parsed'])\n",
        "model_response_parsed_df_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F_KjQ3sXqAEj",
      "metadata": {
        "id": "F_KjQ3sXqAEj"
      },
      "outputs": [],
      "source": [
        "model_response_parsed_df_3 = model_response_parsed_df_3.apply(lambda x: x.astype(str).str.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fudlsBnbHTj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "5fudlsBnbHTj",
        "outputId": "38dd3041-3e8e-4f4f-826d-97df0681e90c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  restaurant_ID  rating_review  \\\n",
              "0        FLV202              5   \n",
              "1        SAV303              5   \n",
              "2        YUM789              5   \n",
              "3        TST101              5   \n",
              "4        EAT456              5   \n",
              "\n",
              "                                         review_full  \\\n",
              "0  Totally in love with the Auro of the place, re...   \n",
              "1  Kailash colony is brimming with small cafes no...   \n",
              "2  Excellent taste and awesome decorum. Must visi...   \n",
              "3  I have visited at jw lough/restourant. There w...   \n",
              "4  Had a great experience in the restaurant food ...   \n",
              "\n",
              "                                      model_response  \\\n",
              "0  {\"Overall\": \"Positive\",\"Food Quality\": \"Positi...   \n",
              "1  {\"Overall\": \"Positive\",\"Food Quality\": \"Positi...   \n",
              "2  {\"Overall\": \"Positive\",\"Food Quality\": \"Positi...   \n",
              "3  {\"Overall\": \"Positive\",\"Food Quality\": \"Not Ap...   \n",
              "4  {\"Overall\": \"Positive\",\"Food Quality\": \"Positi...   \n",
              "\n",
              "                               model_response_parsed   Overall  \\\n",
              "0  {'Overall': 'Positive', 'Food Quality': 'Posit...  positive   \n",
              "1  {'Overall': 'Positive', 'Food Quality': 'Posit...  positive   \n",
              "2  {'Overall': 'Positive', 'Food Quality': 'Posit...  positive   \n",
              "3  {'Overall': 'Positive', 'Food Quality': 'Not A...  positive   \n",
              "4  {'Overall': 'Positive', 'Food Quality': 'Posit...  positive   \n",
              "\n",
              "     Food Quality         Service        Ambience  \n",
              "0        positive        positive        positive  \n",
              "1        positive  not applicable        positive  \n",
              "2        positive        positive        positive  \n",
              "3  not applicable        positive  not applicable  \n",
              "4        positive        positive  not applicable  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5d730d6-1d13-4d00-b7d1-77bcf1065f15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>restaurant_ID</th>\n",
              "      <th>rating_review</th>\n",
              "      <th>review_full</th>\n",
              "      <th>model_response</th>\n",
              "      <th>model_response_parsed</th>\n",
              "      <th>Overall</th>\n",
              "      <th>Food Quality</th>\n",
              "      <th>Service</th>\n",
              "      <th>Ambience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FLV202</td>\n",
              "      <td>5</td>\n",
              "      <td>Totally in love with the Auro of the place, re...</td>\n",
              "      <td>{\"Overall\": \"Positive\",\"Food Quality\": \"Positi...</td>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAV303</td>\n",
              "      <td>5</td>\n",
              "      <td>Kailash colony is brimming with small cafes no...</td>\n",
              "      <td>{\"Overall\": \"Positive\",\"Food Quality\": \"Positi...</td>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>YUM789</td>\n",
              "      <td>5</td>\n",
              "      <td>Excellent taste and awesome decorum. Must visi...</td>\n",
              "      <td>{\"Overall\": \"Positive\",\"Food Quality\": \"Positi...</td>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TST101</td>\n",
              "      <td>5</td>\n",
              "      <td>I have visited at jw lough/restourant. There w...</td>\n",
              "      <td>{\"Overall\": \"Positive\",\"Food Quality\": \"Not Ap...</td>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Not A...</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EAT456</td>\n",
              "      <td>5</td>\n",
              "      <td>Had a great experience in the restaurant food ...</td>\n",
              "      <td>{\"Overall\": \"Positive\",\"Food Quality\": \"Positi...</td>\n",
              "      <td>{'Overall': 'Positive', 'Food Quality': 'Posit...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5d730d6-1d13-4d00-b7d1-77bcf1065f15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5d730d6-1d13-4d00-b7d1-77bcf1065f15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5d730d6-1d13-4d00-b7d1-77bcf1065f15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-892fb4a8-859b-44d7-85e3-5e0225341071\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-892fb4a8-859b-44d7-85e3-5e0225341071')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-892fb4a8-859b-44d7-85e3-5e0225341071 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_with_parsed_model_output_3",
              "summary": "{\n  \"name\": \"data_with_parsed_model_output_3\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"restaurant_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"FLV202\",\n          \"PIZ555\",\n          \"CRV333\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating_review\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_full\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Totally in love with the Auro of the place, really beautiful and quite fancy at the same time. The ambience is very pure and gives a sense of positivity throughout. Outdoor and indoor interior are quite quaint and cute. Love the open kitchen idea and there whole marketplace ideology. Due to coronovirus they specifically use disposable cutlery to keep the pandemic in mind taking all the precautionary measures from the beginning of the place with the mask on their staff and using good sanitisation. The food is really amazing specially the pizza straight from the oven and the hummus and pita bread are quite delicious too. If you're looking for a classy yet soothing Italian place in Delhi,Fatjar is a go to for you!\",\n          \"Whilst staying at the Welcolmhotel Dwarka we visited Pavillion 75 expecting great things but we were disappointed. The place has great trip advisor reviews so we had high expectations that were sadly not met.  What really ruined our nice meal was the self service. A waiter gave us (a party of 5) two tablets to look at the menu on. Unlike with proper menus, where everyone can browse at their own speed we had to share a tablet between 5. We asked the waiter for more tablets and were given one. After we had eventually all used the tablets to browse and input our orders on to one tablet the tablet then had an error message and froze. We used the other tablet to order and that one ran out of battery. We were hungry after a long day travelling this was stressful. Eventually one of the waiters came over and took details of our order. I really disliked this way of ordering food, and would not use the restaurant again because of this.  The table was also dirty, there was dust and bits of fluff on the table and cloth napkins and my aunt was given a chipped glass which she discovered upon taking a drink. We told the waiter and he apologised and got us a new glass but again, this just really made our experience a disappointment.  Very disappointed as seems to have good reviews, maybe we came on a bad day but we didn't like the menu/way of ordering, the table was dirty and a member of our party was given a chipped glass.\",\n          \"SERVICE HORRENDOUS!!!!! Listen to the reviews. Sandwich was decent enough (maybe because I was soooo hungry after a hectic day out) well presented but the service put me off completely. 12 servers on the floor including the manager and not one person came over to check back to make sure all was okay with our meals. All hanging around talking. And when I say 12 that\\u2019s not even an exaggeration. Not a 5 star service. And certainly not a 5 star hotel. We did ask for bottled water and when poured in to a glass you could see tiny bubbles forming and microscopic imperfections on the glass because it was so warm. I asked for cold water and I was told they did not have any? I explained that I will not be drinking the warm water after waiting 15 minutes a new bottle came out...coldish.. 5 star ? And they do not have cold water! Ridiculous. Maybe for further tourist this could be a preference, cold water or temperature. 3700 rupees \\u20ac46 for two sandwiches, bottled water and terrible service! Certainly not worth it. I reckon the street food stalls would give a better service then here \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"{\\\"Overall\\\": \\\"Positive\\\",\\\"Food Quality\\\": \\\"Positive\\\",\\\"Service\\\": \\\"Positive\\\",\\\"Ambience\\\": \\\"Positive\\\"}\",\n          \"{\\\"Overall\\\": \\\"Positive\\\",\\\"Food Quality\\\": \\\"Positive\\\",\\\"Service\\\": \\\"Not Applicable\\\",\\\"Ambience\\\": \\\"Positive\\\"}\",\n          \"{\\\"Overall\\\": \\\"Neutral\\\",\\\"Food Quality\\\": \\\"Neutral\\\",\\\"Service\\\": \\\"Positive\\\",\\\"Ambience\\\": \\\"Positive\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_response_parsed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"neutral\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Food Quality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"positive\",\n          \"not applicable\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Service\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"not applicable\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ambience\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"not applicable\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "data_with_parsed_model_output_3 = pd.concat([data_3, model_response_parsed_df_3], axis=1)\n",
        "data_with_parsed_model_output_3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v6Ktnid1bHTk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v6Ktnid1bHTk",
        "outputId": "19df8717-bf9d-457e-f7d1-220b61ff291f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  restaurant_ID  rating_review  \\\n",
              "0        FLV202              5   \n",
              "1        SAV303              5   \n",
              "2        YUM789              5   \n",
              "3        TST101              5   \n",
              "4        EAT456              5   \n",
              "\n",
              "                                         review_full   Overall  \\\n",
              "0  Totally in love with the Auro of the place, re...  positive   \n",
              "1  Kailash colony is brimming with small cafes no...  positive   \n",
              "2  Excellent taste and awesome decorum. Must visi...  positive   \n",
              "3  I have visited at jw lough/restourant. There w...  positive   \n",
              "4  Had a great experience in the restaurant food ...  positive   \n",
              "\n",
              "     Food Quality         Service        Ambience  \n",
              "0        positive        positive        positive  \n",
              "1        positive  not applicable        positive  \n",
              "2        positive        positive        positive  \n",
              "3  not applicable        positive  not applicable  \n",
              "4        positive        positive  not applicable  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-118aaf02-9817-4e4c-b6ab-3e84dc315c5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>restaurant_ID</th>\n",
              "      <th>rating_review</th>\n",
              "      <th>review_full</th>\n",
              "      <th>Overall</th>\n",
              "      <th>Food Quality</th>\n",
              "      <th>Service</th>\n",
              "      <th>Ambience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FLV202</td>\n",
              "      <td>5</td>\n",
              "      <td>Totally in love with the Auro of the place, re...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAV303</td>\n",
              "      <td>5</td>\n",
              "      <td>Kailash colony is brimming with small cafes no...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>YUM789</td>\n",
              "      <td>5</td>\n",
              "      <td>Excellent taste and awesome decorum. Must visi...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TST101</td>\n",
              "      <td>5</td>\n",
              "      <td>I have visited at jw lough/restourant. There w...</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EAT456</td>\n",
              "      <td>5</td>\n",
              "      <td>Had a great experience in the restaurant food ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>not applicable</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-118aaf02-9817-4e4c-b6ab-3e84dc315c5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-118aaf02-9817-4e4c-b6ab-3e84dc315c5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-118aaf02-9817-4e4c-b6ab-3e84dc315c5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d419c3b9-d7da-445f-b335-287de5a3eeb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d419c3b9-d7da-445f-b335-287de5a3eeb2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d419c3b9-d7da-445f-b335-287de5a3eeb2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_data_3",
              "summary": "{\n  \"name\": \"final_data_3\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"restaurant_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"FLV202\",\n          \"PIZ555\",\n          \"CRV333\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating_review\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_full\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Totally in love with the Auro of the place, really beautiful and quite fancy at the same time. The ambience is very pure and gives a sense of positivity throughout. Outdoor and indoor interior are quite quaint and cute. Love the open kitchen idea and there whole marketplace ideology. Due to coronovirus they specifically use disposable cutlery to keep the pandemic in mind taking all the precautionary measures from the beginning of the place with the mask on their staff and using good sanitisation. The food is really amazing specially the pizza straight from the oven and the hummus and pita bread are quite delicious too. If you're looking for a classy yet soothing Italian place in Delhi,Fatjar is a go to for you!\",\n          \"Whilst staying at the Welcolmhotel Dwarka we visited Pavillion 75 expecting great things but we were disappointed. The place has great trip advisor reviews so we had high expectations that were sadly not met.  What really ruined our nice meal was the self service. A waiter gave us (a party of 5) two tablets to look at the menu on. Unlike with proper menus, where everyone can browse at their own speed we had to share a tablet between 5. We asked the waiter for more tablets and were given one. After we had eventually all used the tablets to browse and input our orders on to one tablet the tablet then had an error message and froze. We used the other tablet to order and that one ran out of battery. We were hungry after a long day travelling this was stressful. Eventually one of the waiters came over and took details of our order. I really disliked this way of ordering food, and would not use the restaurant again because of this.  The table was also dirty, there was dust and bits of fluff on the table and cloth napkins and my aunt was given a chipped glass which she discovered upon taking a drink. We told the waiter and he apologised and got us a new glass but again, this just really made our experience a disappointment.  Very disappointed as seems to have good reviews, maybe we came on a bad day but we didn't like the menu/way of ordering, the table was dirty and a member of our party was given a chipped glass.\",\n          \"SERVICE HORRENDOUS!!!!! Listen to the reviews. Sandwich was decent enough (maybe because I was soooo hungry after a hectic day out) well presented but the service put me off completely. 12 servers on the floor including the manager and not one person came over to check back to make sure all was okay with our meals. All hanging around talking. And when I say 12 that\\u2019s not even an exaggeration. Not a 5 star service. And certainly not a 5 star hotel. We did ask for bottled water and when poured in to a glass you could see tiny bubbles forming and microscopic imperfections on the glass because it was so warm. I asked for cold water and I was told they did not have any? I explained that I will not be drinking the warm water after waiting 15 minutes a new bottle came out...coldish.. 5 star ? And they do not have cold water! Ridiculous. Maybe for further tourist this could be a preference, cold water or temperature. 3700 rupees \\u20ac46 for two sandwiches, bottled water and terrible service! Certainly not worth it. I reckon the street food stalls would give a better service then here \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"neutral\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Food Quality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"positive\",\n          \"not applicable\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Service\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"not applicable\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ambience\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"not applicable\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "final_data_3 = data_with_parsed_model_output_3.drop(['model_response','model_response_parsed'], axis=1)\n",
        "final_data_3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dm8LimPbHTl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "8dm8LimPbHTl",
        "outputId": "dbccea2e-260c-4ae9-b870-79cf74320ef8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Overall\n",
              "positive    8\n",
              "negative    7\n",
              "neutral     5\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Overall</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "final_data_3['Overall'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79rgJ_pObHTm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "79rgJ_pObHTm",
        "outputId": "8f945843-bb60-4b51-fb24-ab8aac440394"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Food Quality\n",
              "positive              6\n",
              "neutral               5\n",
              "not applicable        4\n",
              "negative              3\n",
              "average               1\n",
              "if not exceptional    1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Food Quality</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not applicable</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>if not exceptional</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "final_data_3['Food Quality'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8IllrLC0u1a",
      "metadata": {
        "id": "a8IllrLC0u1a"
      },
      "source": [
        "**Note:** One of the sentiment is 'if not exceptional'. This is most likely positive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-a8rLEt3bHTm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "-a8rLEt3bHTm",
        "outputId": "8c626139-4415-4567-9e99-4a118ce553b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Service\n",
              "negative          10\n",
              "positive           9\n",
              "not applicable     1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Service</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not applicable</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "final_data_3['Service'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-JCcAI2UbHTn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "-JCcAI2UbHTn",
        "outputId": "0b8db238-78b4-44fa-9d81-4c90fc213512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ambience\n",
              "positive          9\n",
              "not applicable    8\n",
              "negative          2\n",
              "neutral           1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ambience</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not applicable</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "final_data_3['Ambience'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RxpHCNQeh3VL",
      "metadata": {
        "id": "RxpHCNQeh3VL"
      },
      "source": [
        "## 4. Identifying Overall Sentiment, Sentiment of Aspects of the Experience, and the Liked/Disliked Features of the Different Aspects of the Experience (Llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VtLikOc_vRsd",
      "metadata": {
        "id": "VtLikOc_vRsd"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data\n",
        "data_4 = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iJVySI-LcX3X",
      "metadata": {
        "id": "iJVySI-LcX3X"
      },
      "outputs": [],
      "source": [
        "# defining the instructions for the model\n",
        "instruction_4 = \"\"\"\n",
        "    You are an AI tasked with analyzing restaurant reviews. Your goal is to classify the overall sentiment of the provided review into the following categories:\n",
        "        - Positive\n",
        "        - Negative\n",
        "        - Neutral\n",
        "\n",
        "    Subsequently, assess the sentiment of specific aspects mentioned in the review, namely:\n",
        "        1. Food quality\n",
        "        2. Service\n",
        "        3. Ambience\n",
        "\n",
        "    Further, identify liked and/or disliked features associated with each aspect in the review.\n",
        "\n",
        "    Return the output in the specified JSON format, ensuring consistency and handling missing values appropriately:\n",
        "\n",
        "    {\n",
        "        \"Overall\": \"your_sentiment_prediction\",\n",
        "        \"Food Quality\": \"your_sentiment_prediction\",\n",
        "        \"Service\": \"your_sentiment_prediction\",\n",
        "        \"Ambience\": \"your_sentiment_prediction\",\n",
        "        \"Food Quality Features\": [\"liked/disliked features\"],\n",
        "        \"Service Features\": [\"liked/disliked features\"],\n",
        "        \"Ambience Features\": [\"liked/disliked features\"]\n",
        "    }\n",
        "\n",
        "    The sentiment prediction for Overall, Food Quality, Service, and Ambience should be one of \"Positive\", \"Negative\", or \"Neutral\" only.\n",
        "    In case one of the three aspects is not mentioned in the review, set \"Not Applicable\" (including quotes) in the corresponding JSON key value for the sentiment.\n",
        "    In case there are no liked/disliked features for a particular aspect, assign an empty list in the corresponding JSON key value for the aspect.\n",
        "    Only return the JSON, do NOT return any other text or information.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pM2Vrx5svRsm",
      "metadata": {
        "id": "pM2Vrx5svRsm"
      },
      "outputs": [],
      "source": [
        "data_4['model_response'] = data_4['review_full'].apply(lambda x: generate_llama_response(instruction_4, x).replace('\\n', ''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pYLMMMdLvRsm",
      "metadata": {
        "id": "pYLMMMdLvRsm"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "print(data_4.loc[i, 'review_full'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fz6EQKwd4_qb",
      "metadata": {
        "id": "fz6EQKwd4_qb"
      },
      "outputs": [],
      "source": [
        "print(data_4.loc[i, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qLyEyL4avRsm",
      "metadata": {
        "id": "qLyEyL4avRsm"
      },
      "outputs": [],
      "source": [
        "# applying the function to the model response\n",
        "data_4['model_response_parsed'] = data_4['model_response'].apply(extract_json_data)\n",
        "data_4['model_response_parsed'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z22aZcPx_NnQ",
      "metadata": {
        "id": "z22aZcPx_NnQ"
      },
      "outputs": [],
      "source": [
        "data_4[data_4.model_response_parsed == {}]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h6GGBy0B_SNK",
      "metadata": {
        "id": "h6GGBy0B_SNK"
      },
      "source": [
        "- There are three model responses that the JSON parser function could not parse\n",
        "- We'll manually add the values for these three responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iO0DtzLh_R1_",
      "metadata": {
        "id": "iO0DtzLh_R1_"
      },
      "outputs": [],
      "source": [
        "print(data_4.loc[3, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZGRD2IVJ_pjt",
      "metadata": {
        "id": "ZGRD2IVJ_pjt"
      },
      "outputs": [],
      "source": [
        "print(data_4.loc[6, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zIlXqANQ__33",
      "metadata": {
        "id": "zIlXqANQ__33"
      },
      "outputs": [],
      "source": [
        "print(data_4.loc[7, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4mKK7kPP__vS",
      "metadata": {
        "id": "4mKK7kPP__vS"
      },
      "outputs": [],
      "source": [
        "upd_val_1 = {\n",
        "    \"Overall\": \"Positive\",\n",
        "    \"Food Quality\": \"Positive\",\n",
        "    \"Service\": \"Positive\",\n",
        "    \"Ambience\": \"Not Applicable\",\n",
        "    \"Food Quality Features\": [],\n",
        "    \"Service Features\": [\"excellent service\"],\n",
        "    \"Ambience Features\": []\n",
        "}\n",
        "\n",
        "upd_val_2 = {\n",
        "    \"Overall\": \"Neutral\",\n",
        "    \"Food Quality\": \"Neutral\",\n",
        "    \"Service\": \"Neutral\",\n",
        "    \"Ambience\": \"Not Applicable\",\n",
        "    \"Food Quality Features\": [\"well prepared\"],\n",
        "    \"Service Features\": [\"slow and inattentive\"],\n",
        "    \"Ambience Features\": [\"interior is friendly\", \"not intimidating\"]\n",
        "}\n",
        "\n",
        "upd_val_3 = {\n",
        "    \"Overall\": \"Neutral\",\n",
        "    \"Food Quality\": \"Positive\",\n",
        "    \"Service\": \"Negative\",\n",
        "    \"Ambience\": \"Positive\",\n",
        "    \"Food Quality Features\": [\"Some tasty, others average\"],\n",
        "    \"Service Features\": [\"Attentive staff\", \"Slow service\"],\n",
        "    \"Ambience Features\": []\n",
        "}\n",
        "\n",
        "# defining the list of indices to update\n",
        "idx_list = [3,6,7]\n",
        "data_4.loc[idx_list, 'model_response_parsed'] = [upd_val_1, upd_val_2, upd_val_3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96TJoxhWhpCs",
      "metadata": {
        "id": "96TJoxhWhpCs"
      },
      "source": [
        "**Note**: The values model responses that cannot be parsed correctly by the JSON parser function may vary with execution due to the randomness associated with LLMs. Kindly update as observed when run in your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-WlHzvoHvRsm",
      "metadata": {
        "id": "-WlHzvoHvRsm"
      },
      "outputs": [],
      "source": [
        "model_response_parsed_df_4 = pd.json_normalize(data_4['model_response_parsed'])\n",
        "model_response_parsed_df_4.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j6i2peyLvRsm",
      "metadata": {
        "id": "j6i2peyLvRsm"
      },
      "outputs": [],
      "source": [
        "data_with_parsed_model_output_4 = pd.concat([data_4, model_response_parsed_df_4], axis=1)\n",
        "data_with_parsed_model_output_4.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hu8LyWsZvRsm",
      "metadata": {
        "id": "Hu8LyWsZvRsm"
      },
      "outputs": [],
      "source": [
        "final_data_4 = data_with_parsed_model_output_4.drop(['model_response','model_response_parsed'], axis=1)\n",
        "final_data_4.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZHNMqvjU2vUd",
      "metadata": {
        "id": "ZHNMqvjU2vUd"
      },
      "outputs": [],
      "source": [
        "final_data_4['Overall'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2YgtXH5_eHuI",
      "metadata": {
        "id": "2YgtXH5_eHuI"
      },
      "outputs": [],
      "source": [
        "final_data_4['Food Quality'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EZaowwqaeHuP",
      "metadata": {
        "id": "EZaowwqaeHuP"
      },
      "outputs": [],
      "source": [
        "final_data_4['Service'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vEuXclkgeHuP",
      "metadata": {
        "id": "vEuXclkgeHuP"
      },
      "outputs": [],
      "source": [
        "final_data_4['Ambience'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0k9WJ3bXxcdz",
      "metadata": {
        "id": "0k9WJ3bXxcdz"
      },
      "source": [
        "## 5. Identifying Overall Sentiment, Sentiment of Aspects of the Experience, Liked/Disliked Features of the Different Aspects of the Experience, and Sharing a Response (Llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iMKm1ZM3xcd0",
      "metadata": {
        "id": "iMKm1ZM3xcd0"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data\n",
        "data_5 = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AuaVtos0xcd0",
      "metadata": {
        "id": "AuaVtos0xcd0"
      },
      "outputs": [],
      "source": [
        "# defining the instructions for the model\n",
        "instruction_5 = \"\"\"\n",
        "    You are an AI analyzing restaurant reviews. Classify the overall sentiment of the provided review into the following categories:\n",
        "    - \"Positive\"\n",
        "    - \"Negative\"\n",
        "    - \"Neutral\"\n",
        "\n",
        "    Once that is done, check for a mention of the following aspects in the review and clasify the sentiment of each aspect as positive, negative, or neutral:\n",
        "    1. Food quality\n",
        "    2. Service\n",
        "    3. Ambience\n",
        "\n",
        "    Once that is done, look for liked and/or disliked features mentioned against each of the above aspects in the review and extract them.\n",
        "\n",
        "    Finally, draft a response for the customer based on the review. Start out with a thank you note and then add on to it as per the following:\n",
        "    1. If the review is positive, mention that it would be great to have them again\n",
        "    2. If the review is neutral, ask them for what the restaurant could have done better\n",
        "    3. If the review is negative, apologive for the inconvenience and mention that we'll be looking into the points raised\n",
        "\n",
        "    Return the output in the specified JSON format, ensuring consistency and handling missing values appropriately Ensure that all values in the JSON are formatted as strings, and each element within the lists should be enclosed in double quotes:\n",
        "\n",
        "    {\n",
        "        \"Overall\": \"your_sentiment_prediction\",\n",
        "        \"Food Quality\": \"your_sentiment_prediction\",\n",
        "        \"Service\": \"your_sentiment_prediction\",\n",
        "        \"Ambience\": \"your_sentiment_prediction\",\n",
        "        \"Food Quality Features\": [\"liked/disliked features\"],\n",
        "        \"Service Features\": [\"liked/disliked features\"],\n",
        "        \"Ambience Features\": [\"liked/disliked features\"],\n",
        "        \"Response\": \"your_response_to_the_customer_review\",\n",
        "    }\n",
        "\n",
        "    The sentiment prediction for Overall, Food Quality, Service, and Ambience should be one of \"Positive\", \"Negative\", or \"Neutral\" only.\n",
        "    In case one of the three aspects is not mentioned in the review, set \"Not Applicable\" (including quotes) in the corresponding JSON key value for the sentiment.\n",
        "    In case there are no liked/disliked features for a particular aspect, assign an empty list in the corresponding JSON key value for the aspect.\n",
        "    Be polite and empathetic in the response to the customer review.\n",
        "    Only return the JSON, do NOT return any other text or information.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7rKhWLJNxcd0",
      "metadata": {
        "id": "7rKhWLJNxcd0"
      },
      "outputs": [],
      "source": [
        "data_5['model_response'] = data_5['review_full'].apply(lambda x: generate_llama_response(instruction_5, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HIGcY1TIxcd0",
      "metadata": {
        "id": "HIGcY1TIxcd0"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "print(data_5.loc[i, 'review_full'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aalA4FCp5Fgj",
      "metadata": {
        "id": "aalA4FCp5Fgj"
      },
      "outputs": [],
      "source": [
        "print(data_5.loc[i, 'model_response'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H5SPJvmIxcd0",
      "metadata": {
        "id": "H5SPJvmIxcd0"
      },
      "outputs": [],
      "source": [
        "# applying the function to the model response\n",
        "data_5['model_response_parsed'] = data_5['model_response'].apply(extract_json_data)\n",
        "data_5['model_response_parsed'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xFVTS6sGxcd0",
      "metadata": {
        "id": "xFVTS6sGxcd0"
      },
      "outputs": [],
      "source": [
        "model_response_parsed_df_5 = pd.json_normalize(data_5['model_response_parsed'])\n",
        "model_response_parsed_df_5.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e58393d",
      "metadata": {
        "id": "7e58393d"
      },
      "outputs": [],
      "source": [
        "model_response_parsed_df_5['Response'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gCyWWNcJxcd0",
      "metadata": {
        "id": "gCyWWNcJxcd0"
      },
      "outputs": [],
      "source": [
        "data_with_parsed_model_output_5 = pd.concat([data_5, model_response_parsed_df_5], axis=1)\n",
        "data_with_parsed_model_output_5.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QER0nBVBxcd1",
      "metadata": {
        "id": "QER0nBVBxcd1"
      },
      "outputs": [],
      "source": [
        "final_data_5 = data_with_parsed_model_output_5.drop(['model_response','model_response_parsed'], axis=1)\n",
        "final_data_5.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V2G6_2HUOlKp",
      "metadata": {
        "id": "V2G6_2HUOlKp"
      },
      "outputs": [],
      "source": [
        "final_data_5['Overall'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_MQaFVC2OlKq",
      "metadata": {
        "id": "_MQaFVC2OlKq"
      },
      "outputs": [],
      "source": [
        "final_data_5['Food Quality'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PICC0XMXOlKr",
      "metadata": {
        "id": "PICC0XMXOlKr"
      },
      "outputs": [],
      "source": [
        "final_data_5['Service'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gZW3RYfmOlKr",
      "metadata": {
        "id": "gZW3RYfmOlKr"
      },
      "outputs": [],
      "source": [
        "final_data_5['Ambience'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H3A46S7Tx_U6",
      "metadata": {
        "id": "H3A46S7Tx_U6"
      },
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "muFFmuCnyA43",
      "metadata": {
        "id": "muFFmuCnyA43"
      },
      "source": [
        "- We used an LLM to do multiple tasks, one stage at a time\n",
        "    1. We first identified the overall sentiment of the review using the LLM\n",
        "    2. We then identified the overall sentiment of the review and got the output in a structured format from the LLM for ease-of-access\n",
        "    3. Next, we identified the overall sentiment of the review as well as sentiment of specific aspects of the experience\n",
        "    4. Next, in addition to the overall sentiment of the review as well as sentiment of specific aspects of the experience, we also identified the liked/disliked features of the different aspects of the experience\n",
        "    5. Finally, in addition to all the above, we also got a response we can share with the customer based on their review\n",
        "\n",
        "- One can manually label the data (overall sentiment and sentiments of different aspects) and then compare the model's output with the same to get a quantitative measure of the models performance.\n",
        "\n",
        "- To try and improve the model performance, one can try the following:\n",
        "    1. Update the prompt\n",
        "    2. Update the model parameters (`temparature`, `top_p`, ...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JJztOYrhx87T",
      "metadata": {
        "id": "JJztOYrhx87T"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "G-jLkpBYdP89",
        "xClk0SOxdU_s",
        "MzSKXh2LsOvd",
        "mgGZFBqvdX3_",
        "b8pDl8uVKR2W",
        "mv_4wV7dTNqQ",
        "H-51wMmpGzcr",
        "jbaduRVymY3v",
        "oWvf3R3An5K4",
        "VVXK7vYfmdkL",
        "CHwEJ-hYjZyw",
        "BhARt3BUmHJA",
        "sq1Aq8BXajfg",
        "ixmkBFZjh3Uu",
        "HslGURoah3VI",
        "Mf4lta2PbHS4",
        "RxpHCNQeh3VL",
        "0k9WJ3bXxcdz",
        "H3A46S7Tx_U6"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "482076d5afeb47ffbb65074c9fd3a9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95883142419e42d68c08abebebc6a1c8",
              "IPY_MODEL_6d73005a4d6a4977ae5d9e6922312ddc",
              "IPY_MODEL_2b3c917ba8254b57a1d8c72b43967c4c"
            ],
            "layout": "IPY_MODEL_42fd98a6d36c4beab4c83a089a5d2c26"
          }
        },
        "95883142419e42d68c08abebebc6a1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce1d39ecec5429abf0f4722301dd7b3",
            "placeholder": "​",
            "style": "IPY_MODEL_53c4aceafee74d60a37d5b163b2fad2a",
            "value": "llama-2-13b-chat.Q5_K_M.gguf: 100%"
          }
        },
        "6d73005a4d6a4977ae5d9e6922312ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef3b58253ba14966a4f784e9c89146e2",
            "max": 9229924224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70122b04cb544875a5c4670616f654b6",
            "value": 9229924224
          }
        },
        "2b3c917ba8254b57a1d8c72b43967c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e70a1ccf5e4fd082ec709966a35fcd",
            "placeholder": "​",
            "style": "IPY_MODEL_8056317650ff4e2a91ac8ae0ee012016",
            "value": " 9.23G/9.23G [01:00&lt;00:00, 219MB/s]"
          }
        },
        "42fd98a6d36c4beab4c83a089a5d2c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce1d39ecec5429abf0f4722301dd7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53c4aceafee74d60a37d5b163b2fad2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef3b58253ba14966a4f784e9c89146e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70122b04cb544875a5c4670616f654b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8e70a1ccf5e4fd082ec709966a35fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8056317650ff4e2a91ac8ae0ee012016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e10da3e09df842f39e9d35e495b80fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_730842aebb4f4c899780aa9df301b8a0",
              "IPY_MODEL_cfb4ba89ffe5492f82cf424bd1d928ff",
              "IPY_MODEL_15bf83f7f2cb4d54b45f2671de69b62b"
            ],
            "layout": "IPY_MODEL_883678895c1d447c8bedf6f22918ef0e"
          }
        },
        "730842aebb4f4c899780aa9df301b8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_618eadc69cd64850a931956f4a31f839",
            "placeholder": "​",
            "style": "IPY_MODEL_540d607ce23e4f5fa1da5878bd03c8ac",
            "value": "mistral-7b-instruct-v0.2.Q6_K.gguf: 100%"
          }
        },
        "cfb4ba89ffe5492f82cf424bd1d928ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f29d30022e45ebba2657b274e4a3f7",
            "max": 5942065440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d5f21a56aee4bfeaec7a8b7003272b6",
            "value": 5942065440
          }
        },
        "15bf83f7f2cb4d54b45f2671de69b62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae9b7e1b22044139218913923ed438e",
            "placeholder": "​",
            "style": "IPY_MODEL_66e9c46f6c01479a917adb2e99e8631f",
            "value": " 5.94G/5.94G [01:42&lt;00:00, 44.6MB/s]"
          }
        },
        "883678895c1d447c8bedf6f22918ef0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618eadc69cd64850a931956f4a31f839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540d607ce23e4f5fa1da5878bd03c8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5f29d30022e45ebba2657b274e4a3f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d5f21a56aee4bfeaec7a8b7003272b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cae9b7e1b22044139218913923ed438e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e9c46f6c01479a917adb2e99e8631f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}